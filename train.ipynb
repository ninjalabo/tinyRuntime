{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf58a11",
   "metadata": {},
   "source": [
    "# ML model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda487a",
   "metadata": {},
   "source": [
    "This notebook creates and trains a simple fully connected model using MNIST dataset. At the end, the model is exported as `model.bin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a66b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from model import ResNetMnist # my model\n",
    "from export import export_model\n",
    "from export import export_modelq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83912d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_dataloaderMNIST(batch_size=32):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    trainset = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    testset = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94fba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaderImagenette(batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(224),        \n",
    "        transforms.ToTensor(),             \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "    #data = torchvision.datasets.Imagenette(\"./data\", download=True)\n",
    "    traindataset = datasets.ImageFolder(root='./data/imagenette2/train', transform=transform)\n",
    "    testdataset = datasets.ImageFolder(root='./data/imagenette2/val', transform=transform)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b894e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_model(model, testloader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vloss = 0.\n",
    "        correct = 0.\n",
    "\n",
    "        # Fetch the first batch\n",
    "        for inputs, targets in testloader:\n",
    "            outputs = model(inputs)\n",
    "            vloss += loss_fn(outputs, targets).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted==targets).sum().item()\n",
    "    \n",
    "    return vloss/len(testloader),  correct/len(testloader.dataset)\n",
    "\n",
    "\n",
    "def train_model(model):  \n",
    "    # training\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    trainloader, testloader = generate_dataloaderMNIST()\n",
    "\n",
    "    for epoch in range(1):\n",
    "\n",
    "        model.train()\n",
    "        tloss = 0\n",
    "        for inputs, targets in trainloader:\n",
    "            opt.zero_grad()\n",
    "            out = model(inputs)\n",
    "            loss = loss_fn(out, targets)\n",
    "            loss.backward()\n",
    "            tloss += loss.item()\n",
    "            opt.step()\n",
    "\n",
    "        tloss = tloss/len(trainloader)\n",
    "        vloss, correct = test_model(model, testloader)\n",
    "\n",
    "        print('LOSS train {} valid {} accuracy {:.5f}'.format(tloss, vloss, correct))\n",
    "    torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58550418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.10019624354364351 valid 0.07671000730594435 accuracy 0.97420\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMnist()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e418333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetMnist(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (group1): GroupOfBlocks(\n",
      "    (group): Sequential(\n",
      "      (0): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "        (act): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (group2): GroupOfBlocks(\n",
      "    (group): Sequential(\n",
      "      (0): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "        (act): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (group3): GroupOfBlocks(\n",
      "    (group): Sequential(\n",
      "      (0): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "        (act): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"model.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c920e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote model.bin\n"
     ]
    }
   ],
   "source": [
    "export_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787525d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
