{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb3df77",
   "metadata": {},
   "source": [
    "# Test dataset generator\n",
    "We will prepare tensor binary files from imagenette (valid) dataset for C runtime here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89c7b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "from export import serialize_fp32\n",
    "\n",
    "# Select number of images include to test set\n",
    "max_images_per_class = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842e7e9",
   "metadata": {},
   "source": [
    "We will eventually generate raw tensor binary files for C runtime as a `test` dataset. Those files have a file extension `.bin`. The name of parent direcotries have been already encoded from `0` to `9` accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b88c7",
   "metadata": {},
   "source": [
    "## Generating test set\n",
    "Testset will be saved to huggingface, so you need to clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "efb0c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'imagenette2-320' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/datasets/ninjalabo/imagenette2-320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "142c2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Imagenette dataset\n",
    "path = untar_data(URLs.IMAGENETTE_320,data=Path.cwd()/'data')\n",
    "dls = ImageDataLoaders.from_folder(path, valid='val', item_tfms=Resize(224),\n",
    "                                   batch_tfms=Normalize.from_stats(*imagenet_stats),)\n",
    "\n",
    "# Initialize counters to track saved images per class\n",
    "saved_counts = {str(i): 0 for i in range(10)}\n",
    "\n",
    "for imgs, labels in dls.valid:\n",
    "    for img, label in zip(imgs, labels):\n",
    "        label = str(label.item())  # Convert label to string\n",
    "        if saved_counts[label] < max_images_per_class:\n",
    "            dst_dir = os.path.join(\"imagenette2-320/test\", label)\n",
    "            file_path = os.path.join(dst_dir, f'{saved_counts[label]}.bin')\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                serialize_fp32(f, img)\n",
    "            saved_counts[label] += 1\n",
    "    # Stop if all classes have 10 images\n",
    "    if all(count >= max_images_per_class for count in saved_counts.values()):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3ca15",
   "metadata": {},
   "source": [
    "## Test dataset directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2cd08fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/imagenette2-320/test\u001b[0m\n",
      "├── \u001b[01;34m0\u001b[0m\n",
      "├── \u001b[01;34m1\u001b[0m\n",
      "├── \u001b[01;34m2\u001b[0m\n",
      "├── \u001b[01;34m3\u001b[0m\n",
      "├── \u001b[01;34m4\u001b[0m\n",
      "├── \u001b[01;34m5\u001b[0m\n",
      "├── \u001b[01;34m6\u001b[0m\n",
      "├── \u001b[01;34m7\u001b[0m\n",
      "├── \u001b[01;34m8\u001b[0m\n",
      "└── \u001b[01;34m9\u001b[0m\n",
      "\n",
      "11 directories\n",
      "-rw-r--r--  1 harukadoyu  staff  602112 May 16 13:57 data//imagenette2-320/test/2/3.bin\n",
      "-rw-r--r--  1 harukadoyu  staff  602112 May 16 13:58 data//imagenette2-320/test/2/7.bin\n",
      "-rw-r--r--  1 harukadoyu  staff  602112 May 16 13:35 data//imagenette2-320/test/6/3.bin\n",
      "-rw-r--r--  1 harukadoyu  staff  602112 May 16 13:36 data//imagenette2-320/test/6/7.bin\n"
     ]
    }
   ],
   "source": [
    "!tree -d data/imagenette2-320/test\n",
    "!ls -al data//imagenette2-320/test/[2,6]/[3,7].bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d05d9f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "493a91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from train import load\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        for label in self.classes:\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            files = os.listdir(label_dir)\n",
    "            for file in files:\n",
    "                self.file_paths.append(os.path.join(label_dir, file))\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.file_paths[idx], \"rb\") as f:\n",
    "            nch, h, w = 3, 224, 224\n",
    "            tensor = torch.tensor(struct.unpack(\"f\"*nch*h*w, f.read())).view(nch,h,w)\n",
    "        label = self.labels[idx]\n",
    "        return tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4e1d2bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7fdc1a0a184649bcf04ec6b7c064a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = load(\"resnet18\")\n",
    "learn.dls = DataLoaders(DataLoader([]), test_dl)\n",
    "test_dl = DataLoader(TensorDataset(\"imagenette2-320/test/\"), batch_size=32, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f022a1d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.5 ms, sys: 100 ms, total: 162 ms\n",
      "Wall time: 866 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.07589495182037354,0.9700000286102295]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "learn.model.cpu()\n",
    "learn.validate(dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7439ed",
   "metadata": {},
   "source": [
    "## Upload updated dataset to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "25762d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to update test data set\n",
    "#!cd imagenette2-320/ & git add test & git commit -m \"update test set\" & git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb6d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
